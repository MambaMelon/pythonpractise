
1.高信息熵:表示随机变量x是均匀分布的
2.低信息熵:表示随机变量x各种取值不是等概率出现

3.条件熵:在给定条件x的前提下,随机变量y的信息熵就叫做条件熵H(Y|X)

4.决策树:有监督分类算法
    在已知各种情况发生概率的基础上,通过构建决策树来进行分析的一种的方式
是一种直观应用概率分析的一种图解法.
    决策树内部每个节点表示属性的测试,每个分支表示一个测试输出,每个叶节点
代表一种类别.

5.决策树分为两类:分类树和回归树.前者用于分类标签值,后者用于预测连续值.

6.决策树构建:关键步骤在于分裂属性.是指在某个节点按照某一类特征属性的不同划分构建不同
分支,最终目的是让各个分裂子集纯度高.纯:让一个分裂子类中的待分类的项尽可能的属于同一个级别.
    1)将所有的特征看成一个一个的节点;
    2)遍历每个特征的每一种分割方式,找到最好的分割点;将数据划分为不同的子节点，eg：N1、
        N2....Nm;计算划分之后所有子节点的'纯度'信息;
    3)对第二步产生的分割,选择出最优的特征以及最优的划分方式;得出最终的子节点:N1、N2....Nm
    4)对子节点N1、N2....Nm分别继续执行2-3步,直到每个最终的子节点都足够'纯'.

7.决策树量化纯度:Gini系数,熵,错误率.三个值越大,表示数据纯度越低.
8.信息增益度:
    当计算出各个特征的量化纯度值后,使用信息增益度来选择出当前数据集的分割特征属性.如果信息增益度
越大,表示在该特征属性上会损失的纯度越大,那么该属性就应该在决策树的上层.计算公式为:
    H(D)-H(D|A)
9.决策树的停止条件:
    1)每个节点只有一种类型的时候停止构建
    2)当前节点中记录数小于某个阈值,同时迭代次数达到给定值时
10.决策树效果评估
    采用混淆矩阵计算准确率等指标
    计算叶子节点的纯度值总和

11.ID3算法:每次迭代选择信息增益最大的特征属性作为分割属性
    该算法只支持离线的特征属性
    该算法构建的是多叉树
    优点:
        构建快速简单
    缺点:
        依赖于特征数目较多的特征
        不是递增算法
        单变量决策树,不会考虑特征之间的关联
        抗燥性差
        需要将数据加载到内存

12.C4.5算法:优化的ID3算法,使用信息增益率替代信息增益.在树的构造过程中会进行剪枝等优化操作.
    还能够完成连续数据的离散化处理.

13.CART算法:使用基尼系数作为数据纯度的量化指标来构建的决策树算法就叫做CART
    (Classification And Regression Tree，分类回归树)算法

14.算法优化
    剪枝操作:前置剪枝、后置剪枝
        预剪枝:预剪枝就是在构造决策树的过程中,先对每个结点在划分前进行估计,若果当前结点的划分不能
            带来决策树模型泛华性能的提升,则不对当前结点进行划分并且将当前结点标记为叶结点.
        后剪枝:后剪枝就是先把整颗决策树构造完毕,然后自底向上的对非叶结点进行考察,若将该结点对应的
            子树换为叶结点能够带来泛华性能的提升,则把该子树替换为叶结点.

    随机森林

15.数据标准化
    # StandardScaler (基于特征矩阵的列，将属性值转换至服从正态分布)
    # 标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下
    # 常用与基于正态分布的算法，比如回归

16.数据归一化
    # MinMaxScaler （区间缩放，基于最大最小值，将数据转换到0,1区间上的）
    # 提升模型收敛速度，提升模型精度
    # 常见用于神经网络

17.Normalizer （基于矩阵的行，将样本向量转换为单位向量）
    # 其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准
    # 常见用于文本分类和聚类、logistic回归中也会使用，有效防止过拟合

18.特征选择：从已有的特征中选择出影响目标值最大的特征属性
    # 常用方法：{ 分类：F统计量、卡方系数，互信息mutual_info_classif
    # { 连续：皮尔逊相关系数 F统计量 互信息mutual_info_classif
    # SelectKBest（卡方系数）

19.降维：对于数据而言，如果特征属性比较多，在构建过程中，会比较复杂，这个时候考虑将多维（高维）映射到低维的数据
    #常用的方法：
    #PCA：主成分分析（无监督）
    #LDA：线性判别分析（有监督）类内方差最小，人脸识别，通常先做一次pca